*****************
NOTE: there is extra code added at the end by MF in June 2015. 
This should be integrated into the main code before running this again.
*****************

SELECT A1.grid_id, A1.i, A1.j, A1.year, 
       A1.s10, A1.s50, A1.s80, A1.s100, A1.s200,
       T1.turbine_id,(T1.v_avg_200m/T1.v_avg_1km) AS ratio,
       ((T1.v_avg_200m/T1.v_avg_1km)*A1.s10) AS v_200m_s10,
       ((T1.v_avg_200m/T1.v_avg_1km)*A1.s50) AS v_200m_s50,
       ((T1.v_avg_200m/T1.v_avg_1km)*A1.s80) AS v_200m_s80,
       ((T1.v_avg_200m/T1.v_avg_1km)*A1.s100) AS v_200m_s100,
       ((T1.v_avg_200m/T1.v_avg_1km)*A1.s200) AS v_200m_s200
  FROM annual_average A1, turbine_location_properties T1
  WHERE (A1.grid_id = 'E' 
  AND A1.i = T1.i_1km AND A1.j = T1.j_1km);


SELECT grid_id, i, j, date, hour, tsfc, psfc, pcp, q2m, dswrf, dlwrf, 
       t10, s10, w10, t50, s50, w50, t80, s80, w80, t100, s100, w100, 
       t200, s200, w200
  FROM hourly_average where grid_id='D' and i=5 and j=5 order by date, hour;


CREATE TABLE turbine
(
  grid_id character(1),
  turbine_id integer NOT NULL,
  x_turbine double precision,
  y_turbine double precision,
  i_1km smallint,
  j_1km smallint,
  v_avg_200m real,
  v_avg_1km real,
  speed_ratio real,
  elevation integer,
  CONSTRAINT turbine_id_pkey PRIMARY KEY (turbine_id)
)
WITH (
  OIDS=FALSE
);
ALTER TABLE turbine
  OWNER TO admin;

SELECT grid_id, i, j, to_timestamp(date||hour, 'YYYYMMDDHH24HST8PDT'), hour,date||hour as trial , tsfc, psfc, pcp, q2m, dswrf, dlwrf, 
       t10, s10, w10, t50, s50, w50, t80, s80, w80, t100, s100, w100, 
       t200, s200, w200
  FROM hourly_average1;

SELECT grid_id, i, j, to_timestamp(date||hour, 'YYYYMMDDHH24HST')::timestamp without time zone, hour,date||hour as trial , tsfc, psfc, pcp, q2m, dswrf, dlwrf, 
       t10, s10, w10, t50, s50, w50, t80, s80, w80, t100, s100, w100, 
       t200, s200, w200
  FROM hourly_average1;

UPDATE turbin_hourly SET timestamp = to_timestamp(date||hour, 'YYYYMMDDHH24HST')::timestamp without time zone;

SET DATESTYLE TO SQL;
(Can change to ISO)

SET DATESTYLE TO SQL;
SET TIME ZONE 'UTC';


CREATE TABLE turbine_hourly AS
	SELECT T1.turbine_id, A1.grid_id, A1.i, A1.j, A1.date, A1.hour, A1.tsfc,
        	T1.turbine_id,(T1.v_avg_200m/T1.v_avg_1km) AS ratio,
        	(T1.speed_ratio*A1.s10) AS v_200m_s10,
        	(T1.speed_ratio*A1.s50) AS v_200m_s50,
        	(T1.speed_ratio*A1.s80) AS v_200m_s80,
        	(T1.speed_ratio*A1.s100) AS v_200m_s100,
        	(T1.speed_ratio*A1.s200) AS v_200m_s200
  	FROM hourly_average A1, turbine T1
  	WHERE (A1.grid_id = 'E' 
  	AND T1.i_1km = A1.i AND T1.j_1km = A1.j);


******************************************************************************************************
Original Configuration in postgresql.config file

datestyle = 'iso, mdy'
#intervalstyle = 'postgres'
timezone = 'US/Hawaii'
******************************************************************************************************

******************************************************************************************************
Modified Configuration in postgresql.config file

datestyle = 'sql, mdy'
#intervalstyle = 'postgres'
timezone = 'UTC'
******************************************************************************************************

SELECT * FROM hourly_trial WHERE extract(day from timestamp1)=03;
SELECT DISTINCT timestamp1 FROM hourly_trial where extract(hour from timestamp1)=16;
SELECT DISTINCT timestamp FROM turbine_hourly where extract(year from timestamp)=2007 order by timestamp;

******************************************************************************************************
(CREATE Temporary turb_temp Table to store the turbine_id and the caluculated avg_s80 from the turbine_hourly
table from the years 2007 and 2008 excluding the one day of 2009 grouped by Turbine ID)

CREATE TABLE turb_temp AS
(SELECT turbine_id, 
AVG (v_200m_s80) AS avg_s80, SUM(v_200m_s80):: double precision, COUNT(v_200m_s80)
FROM turbine_hourly
WHERE extract(year from timestamp)=2007 OR extract(year from timestamp)=2008 
GROUP BY turbine_id);
******************************************************************************************************


******************************************************************************************************
(UPDATE the turbine table with the avg_s80 values from the Table turb_temp)

UPDATE turbine SET (avg_s80,turbine_id_trial) = (turb_temp.avg_s80, turb_temp.turbine_id) 
FROM turb_temp
WHERE turbine.turbine_id = turb_temp.turbine_id;
******************************************************************************************************

(TRIAL CODE)
ALTER TABLE hourly_trial ADD COLUMN day_name character(4);

UPDATE hourly_trial
SET day_name = CASE
			WHEN extract(day from timestamp1) = 01 THEN 'MOND'
			WHEN extract(day from timestamp1) = 02 THEN 'TUES'
			WHEN extract(day from timestamp1) = 03 THEN 'WEDN'
			ELSE 'OTR'
		END;


******************************************************************************************************
ALTER TABLE turbine ADD COLUMN turb_model character(4), ADD COLUMN turb_class_type smallint;

UPDATE turbine
SET turb_model = CASE
			WHEN avg_s80 >= 10 THEN 'C89'
			WHEN avg_s80 >= 8.5 AND avg_s80 < 10  THEN 'C93'
			WHEN avg_s80 >= 7.5 AND avg_s80 < 8.5 THEN 'C96'
			WHEN avg_s80 >= 6.0 AND avg_s80 < 7.5 THEN 'C99'
			ELSE 'C99'
		END;

UPDATE turbine
SET turb_class_type = CASE
			WHEN turb_model = 'C89' THEN 1
			WHEN turb_model = 'C93' THEN 2
			WHEN turb_model = 'C96' THEN 3
			WHEN turb_model = 'C99' THEN 4
			ELSE 4
		END;
******************************************************************************************************


******************************************************************************************************
UPDATE turbine_hourly SET windpower = WindPower(turbine.turb_class_type,turbine_hourly.v_200m_s80,(turbine.elevation+turbine.turb_height),turbine_hourly.tsfc)
FROM turbine
WHERE turbine_hourly.turbine_id = turbine.turbine_id;

Query returned successfully: 19518048 rows affected, 670457 ms execution time.
******************************************************************************************************


******************************************************************************************************
CREATE TABLE turb_power_temp AS
(SELECT turbine_id, 
AVG (windpower) AS avg_windpower, SUM(windpower):: double precision, COUNT(windpower)
FROM turbine_hourly
WHERE extract(year from timestamp)=2007 OR extract(year from timestamp)=2008 
GROUP BY turbine_id);
******************************************************************************************************

595.496907074535(2007) + 484.947772143838(2008)

******************************************************************************************************
UPDATE turbine SET (avg_windpower) = (turb_power_temp.avg_windpower) 
FROM turb_power_temp
WHERE turbine.turbine_id = turb_power_temp.turbine_id;
******************************************************************************************************

******************************************************************************************************
UPDATE turbine SET annual_avg_capacity_factor = (avg_windpower/2500);
******************************************************************************************************


annual_avg_capacity_factor >=0.283 AND annual_avg_capacity_factor < 0.379 AND cluster_id is NULL

CREATE TABLE cluster AS
	SELECT  T1.grid_id, T1.turbine_id, T1.date, T1.hour, T1.timestamp, T1.windpower,
        	(T1.windpower/2500) AS hourly_capacity_factor,
        	 A1.cluster_id
  	FROM turbine_hourly T1, turbine_cluster A1
  	WHERE (T1.grid_id = A1.grid_id 
  	AND T1.turbine_id = A1.turbine_id );


CREATE TABLE cluster AS
	SELECT  T1.cluster_id, AVG(A1.x_turbine) AS lat, AVG(A1.y_turbine) AS lon, 
	(2.5*count( DISTINCT T1.turbine_id )) AS size_MW
  	FROM cluster_turbine T1, turbine A1
  	WHERE (T1.grid_id = A1.grid_id 
  	AND T1.turbine_id = A1.turbine_id )
  	GROUP BY T1.cluster_id;

(For Verifying the above table use
 SELECT distinct A1.turbine_id, A1.x_turbine AS lat, A1.y_turbine AS lon
FROM cluster_turbine T1, turbine A1
WHERE A1.turbine_id IN (SELECT turbine_id
  	FROM cluster_turbine T1
  	WHERE T1.cluster_id=101) and T1.cluster_id=101;
)

Add a column "interconnect_id" to cluster table and set it to "1" which is "Honolulu" and can be referenced from the "interconnect" table.
UPDATE cluster SET interconnect_id = 1;

CREATE TABLE interconnect

(
  interconnect_id integer NOT NULL,
 
   county text,
  lat double precision,

   lon double precision,
  
   CONSTRAINT interconnect_id_pkey PRIMARY KEY (interconnect_id)
);

-- At some point interconnect was filled in with the equivalent of the following command.
-- The original code is missing, but these appear to be the population-weighted centers of each county.
INSERT INTO interconnect (interconnect_id, county, lat, lon) VALUES 
    (1, 'Honolulu', 21.372464, -157.913673),
    (2, 'Hawaii', 19.672837, -155.421895),
    (3, 'Maui', 20.863747, -156.493816),
    (4, 'Kauai', 22.021022, -159.442112),
    (5, 'Kalawao', 21.188495, -156.979972);

CREATE TABLE cluster_hourly AS
	SELECT  T1.cluster_id, A1.timestamp, 
	SUM(A1.windpower)/SUM(2500) AS capacity_factor 
  	FROM cluster_turbine T1, turbine_hourly A1
  	WHERE (T1.grid_id = A1.grid_id 
  	AND T1.turbine_id = A1.turbine_id )
  	GROUP BY T1.cluster_id, A1.timestamp;


-----------------------------------------------------------------------------------------
-- NOTE: Matthias Fripp moved all Central Tracking PV (central_pv) code from here
-- to DB_Code/tracking_PV/TrackingPV_Duffie_Horizontal_NS_aligned_Panels_and_Troughs_7.py
-- on 2015-12-13, since it was incomplete and we needed to write code to cluster
-- the sites (instead of one project per km cell)
-- THAT CODE SHOULD BE RUN BEFORE CONTINUING THIS SCRIPT.
-----------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------
-- NOTE: Matthias Fripp removed a small amount of distributed PV code from here on 
-- 2015-12-13 because it duplicated code already in 
-- DB_Code/tracking_PV/SolarPowerHourly.py (from 2014-06-24 or earlier)
-- This code creates the cell_pv_power_hourly table.
-- THAT CODE SHOULD BE RUN BEFORE CONTINUING THIS SCRIPT.
-----------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------
-- MF note 2015-12-30

-- connect_cost table is created in DB_Code/ConnectCost/connect_cost.py, using 0 for connect_length_km 
-- and 0 for connect_cost_per_kw, for everything in the max_capacity table. It looks like this was
-- originally run after all technologies (Wind, DistPV and CentralPV) were added to max_capacity,
-- and before the code below here.

-- We seem to have lost the code to create connect_distance_temp.
-- This contains connect_length_km for all Wind and CentralPV sites.
-- This is probably found by calculating the distance from the site 
-- to the interconnect specified for the same county.
-- lat & lon may come from the cluster table (for wind turbines) 
-- and cell_central_pv_capacity <-> cell (for CentralPV)

-- TODO: integrate connect_cost.py with this code
-- TODO: include lat, lon, interconnect ID, connect_length_km and connect_cost_per_kw in max_capacity itself
-- TODO: also take note of additional "To Do" from Paritosh about connect_costs and "connection cost" below
-----------------------------------------------------------------------------------------

UPDATE connect_cost SET connect_length_km = connect_distance_temp.connect_length_km
FROM connect_distance_temp
WHERE connect_cost.technology = connect_distance_temp.technology AND 
	connect_cost.site = connect_distance_temp.site;


CREATE TABLE "study_date"(period smallint, study_date int, month_of_year smallint, 
date date, hours_in_sample smallint)

CREATE TABLE thours (offset1 smallint)

INSERT INTO thours (offset1) VALUES (0-23);

DELETE FROM timport 
WHERE rowdata NOT LIKE '178,%'

UPDATE timport SET date_time =  CAST(split_part(rowdata, ',', 6) || ' ' || trim(both '"' from (split_part(rowdata, ',', 7)))as timestamp with time zone)

SELECT (D.date_time + ((T.offset1 || ' hours')::interval)) as date_new
from timport D, thours T


CREATE TABLE system_load1 AS 
(SELECT load_zone, 
(C.date_time + ((T.offset1 || ' hours')::interval)) as date_time,
(CAST(trim(both '"' FROM split_part(C.rowdata,',',(8+T.offset1))) AS REAL)) AS system_load
FROM timport C, thours T )


DELETE FROM system_load1
WHERE extract(year from date_time) IN (2006,2009,2010,2011)

UPDATE system_load_Scale SET avg_hist = 
(SELECT AVG(L.system_load)
FROM system_load L
WHERE extract(year from date_time) = 2007)
WHERE year_hist = 2007 AND load_zone ='Oahu'

UPDATE system_load_Scale SET avg_hist = 
(SELECT AVG(L.system_load)
FROM system_load L
WHERE extract(year from date_time) = 2008)
WHERE year_hist = 2008 AND load_zone ='Oahu'

UPDATE system_load_Scale SET peak_hist = 
(SELECT MAX(L.system_load)
FROM system_load L
WHERE extract(year from date_time) = 2007)
WHERE year_hist = 2007 AND load_zone ='Oahu'

UPDATE system_load_Scale SET peak_hist = 
(SELECT MAX(L.system_load)
FROM system_load L
WHERE extract(year from date_time) = 2008)
WHERE year_hist = 2008 AND load_zone ='Oahu'

UPDATE system_load_scale SET scale = ((peak_fore - avg_fore)/(peak_hist - avg_hist))

UPDATE system_load_scale SET offset = (peak_fore - (scale * peak_hist))



CREATE TABLE system_load_2012 AS
(SELECT * from system_load 
WHERE extract(year from date_time) = 2012)


DELETE FROM connect_cost
WHERE TECHNOLOGY IN ('Reciprocating','SCCT_Biodiesel','CCCT_Biodiesel','CCCT_LNG','SCCT_LNG')


ALTER TABLE generator_costs ADD COLUMN distributed smallint

UPDATE generator_costs SET distributed = 1
WHERE technology = 'Wind'

UPDATE generator_costs SET distributed = 0
WHERE technology NOT IN ('Wind')

DELETE FROM connect_cost 
WHERE site=175 AND technology='CentralPV'

(To Do : Have to update the connect_costs table with connect_length_km with the recent values as the equivalent 
sites for exixting plants have been removed from the master tables)

TODO: add connection cost for CentralTrackingPV

*************************************************************************************
12.53% Energy Losses for Wind Turbines have been included in the capacity factor. 
------------------------------------------
The losses include [From HECO IRP Appendix K, page K-67] :
Array : 8.0%
Blade Soiling : 1.0%
Control & Turbulence : 2.0%
Line Losses = 2.0%
------------------------------------------
Total = 1-[(1-Loss1)(1-Loss2).......] =  12.526768% ~ 12.53%

UPDATE cap_factor SET cap_factor = (cap_factor*0.8747)
WHERE technology = 'Wind';

UPDATE cap_factor_old SET cap_factor = (cap_factor*0.8747)
WHERE technology = 'Wind';

UPDATE existing_plants_cap_factor SET cap_factor = (cap_factor*0.8747)
WHERE technology = 'Wind';

UPDATE existing_plants_cap_factor_old SET cap_factor = (cap_factor*0.8747)
WHERE technology = 'Wind';

***************************************************************************************
#Changed Capital Cost for DistPV from $5604 to $4000 as per Dr. Makena Coffman's input.
update generator_costs set capital_cost_per_kw = 4000
where technology = 'DistPV'

***************************************************************************************
------------------------------------------------
-- Add by Matthias Fripp 2015-09-27
-- generator_costs incorrectly uses data from a LM6000 PG in combined cycle mode (HECO IRP App. K table L-6c/L-7c)
-- as the parameters for a LM6000 PG used in simple-cycle mode (which should be HECO IRP App. K table L-2).
-- While we're at it, we eliminate the distinction between LNG and diesel plants (since the current version
-- of SWITCH-Hawaii allows fuel switching to any higher grade).
-- NOTE: the IRP quotes different costs for plants running on LNG or biodiesel. But we use a single plant
-- technology for both. If we use the higher biodiesel costs, that will be slightly prejudicial against
-- a LNG-heavy solution. But if we use the lower LNG costs, it will make biodiesel look slightly cheaper
-- than it really is. So we split the difference and call it a Diesel plant.
-- NOTE: There is no UIF in App. K for LM6000 running as CT on LNG (L-2 uses biodiesel). However, boxes at the
-- bottom of L-7c quote O&M for the plant in LNG mode.

-- TODO: should capital costs and fixed O&M be based on plant gross rating rather than net? (currently using net)
-- TODO: integrate this with other code to import the HECO IRP generator parameters.

update generator_costs set 
  technology = 'CCCT',
  capital_cost_per_kw = (3627+3393)/2,
  connect_cost_per_kw_generic = (136+139)/2,
  fixed_o_m = (63.51+64.04)/2,
  variable_o_m = (0.0126+0.00819)/2,
  heat_rate = (7630+7657)/2,
  fuel = 'Diesel'
  where technology = 'CCCT_LNG';
delete from generator_costs where technology = 'CCCT_Biodiesel';

update generator_costs set 
  technology = 'SCCT',
  capital_cost_per_kw = 2924-124,
  connect_cost_per_kw_generic = 124,
  fixed_o_m = (22.02+22.01)/2,
  variable_o_m = (14.38+10.06)/1000/2,
  heat_rate = 10112,
  fuel = 'Diesel'
  where technology = 'SCCT_LNG';
delete from generator_costs where technology = 'SCCT_Biodiesel';

------------------------------------------------


Added by Matthias Fripp 2015-06-18:
(this should be integrated into earlier code in the future)

create index dz on cap_factor (date_time, load_zone);

Insert past years into system_load_scale so they can be used for historical tests.
(testing past systems using weather patterns from 2007-2008)
TODO: get scale factors for 2009-2011, and use historical scale factors for 2012-15
instead of IRP forecasts.
In the future, it would be easier to tabulate the historical averages and peaks along with
forecast ones, and then create system_loads_scale with "forecasts" for all years.
DROP TABLE IF EXISTS t_hist_loads;
-- get one copy of the historical data
CREATE TEMPORARY TABLE t_hist_loads AS 
    SELECT load_zone, year_hist as year, peak_hist as peak, avg_hist as avg
    FROM system_load_scale 
    WHERE load_scen_id = 'med' AND year_fore = 2015;
-- cross-join the historical data to itself (within each load zone)
-- to create a "forecast" for each historical year
INSERT INTO system_load_scale 
    (load_zone, year_hist, load_scen_id, year_fore, peak_hist, peak_fore, avg_hist, avg_fore, scale)
    SELECT h.load_zone, h.year as year_hist, 'hist' as load_scen_id, 
        f.year as year_fore, h.peak as peak_hist, f.peak as peak_fore, 
        h.avg as avg_hist, f.avg as avg_fore,
        (f.peak - f.avg)/(h.peak - h.avg) as scale
    FROM t_hist_loads h join t_hist_loads f using (load_zone);
UPDATE system_load_scale 
    SET "offset" = (peak_fore - (scale * peak_hist)) WHERE "offset" is null;

Add generator unit sizes for new technologies (omitted from original data import).
alter table generator_costs add column unit_size double precision;

=====================
postgresql doesn't have a "drop [temporary] table if exists" command, so this function does
something similar. This could be useful during data export (and maybe at other times). 

CREATE or REPLACE FUNCTION public.drop_temporary_table(varchar)
RETURNS pg_catalog.bool AS
$BODY$
DECLARE
BEGIN
	 /* check that a temporary table with this name exists and is visible to the current user */
	PERFORM n.nspname, c.relname
	FROM pg_catalog.pg_class c 
		LEFT JOIN pg_catalog.pg_namespace n ON n.oid=c.relnamespace
		WHERE n.nspname like 'pg_temp_%' AND pg_catalog.pg_table_is_visible(c.oid)
			AND Upper(relname) = Upper($1);
	IF FOUND THEN
		EXECUTE 'DROP TABLE ' || $1 || ';';
		RETURN TRUE;
	ELSE
		RETURN FALSE;
	END IF;
END;
$BODY$
LANGUAGE 'plpgsql' VOLATILE;

later, this can be run as 
DO $$ BEGIN PERFORM drop_temporary_table('t'); END $$;
===========================

#### extend system_load_scale to 2050, assuming same conditions from 2033 onward.
# note: this would be easier and more robust in python, because you wouldn't have to 
# hard-code the column names into the query
# NOTE: the PL/PGSQL commands below should do the same job as the direct query, 
# but they are not really easier to read!
# DO $$
# DECLARE
#     last_year integer;
# BEGIN
#     SELECT MAX(year_fore) FROM system_load_scale INTO last_year;
#     RAISE NOTICE 'Adding records after % to system_load_scale', last_year;
#     EXECUTE '
#         INSERT INTO system_load_scale
#             SELECT load_zone, year_hist, load_scen_id,
#                 f.year as year_fore,
#                 peak_hist, peak_fore, avg_hist, avg_fore, scale, offset
#             FROM system_load_scale s
#                 CROSS JOIN generate_series($1+1, 2050) as f(year)
#             WHERE s.year_fore = $1;
#     ' USING last_year
# END
# $$;
INSERT INTO system_load_scale
    SELECT load_zone, year_hist, load_scen_id, 
        f.year as year_fore, 
        peak_hist, peak_fore, avg_hist, avg_fore, scale, "offset"
    FROM system_load_scale s
        CROSS JOIN generate_series((SELECT MAX(year_fore) as last_year FROM system_load_scale)+1, 2050) 
            AS f(year)
    WHERE s.year_fore = (SELECT MAX(year_fore) as last_year FROM system_load_scale);

-- create a "flat" load scenario, with 2015 load levels continuing into the future
DO $$ BEGIN PERFORM drop_temporary_table('t_flat_load'); END $$;
CREATE TEMPORARY TABLE t_flat_load AS 
    SELECT * FROM system_load_scale WHERE load_scen_id = 'med';
UPDATE t_flat_load f
    SET load_scen_id='flat',
        peak_fore = s.peak_fore, avg_fore = s.avg_fore, scale = s.scale, "offset" = s."offset"
    FROM system_load_scale s
    WHERE s.load_scen_id=f.load_scen_id AND s.year_fore = 2015
        AND s.load_zone=f.load_zone AND s.year_hist=f.year_hist;
-- select * from t_flat_load where load_zone='Oahu'  order by year_hist, year_fore;
INSERT INTO system_load_scale SELECT * from t_flat_load;


------------------ Rename technologies for use with new PSIP data (2016-05-08) -----------------
------------------ Run this before running import_data.py
\timing
SET maintenance_work_mem = '4GB';
update max_capacity 
    set technology = case technology
        when 'DistPV_peak' then 'DistPV'
        when 'Wind' then 'OnshoreWind'
        when 'CentralPV' then 'CentralFixedPV'
    end
    where technology in ('DistPV_peak', 'Wind', 'CentralPV');
update connect_cost 
    set technology = case technology
        when 'DistPV_peak' then 'DistPV'
        when 'Wind' then 'OnshoreWind'
        when 'CentralPV' then 'CentralFixedPV'
    end
    where technology in ('DistPV_peak', 'Wind', 'CentralPV');

-- note: dropping and rebuilding the indexes takes about 20 mins, 
-- but the update takes several hours or more with the indexes in place
alter table cap_factor drop constraint dztos;
drop index if exists dztos;
drop index if exists ztsod;
\d cap_factor
-- make sure there are no indexes left

update cap_factor 
    set technology = case technology
        when 'DistPV_peak' then 'DistPV'
        when 'Wind' then 'OnshoreWind'
        when 'CentralPV' then 'CentralFixedPV'
    end
    where technology in ('DistPV_peak', 'Wind', 'CentralPV');
CREATE UNIQUE INDEX dztos ON cap_factor (date_time, load_zone, technology, orientation, site);
CREATE UNIQUE INDEX ztsod ON cap_factor (load_zone, technology, site, orientation, date_time);
ALTER TABLE cap_factor ADD PRIMARY KEY USING INDEX dztos;
